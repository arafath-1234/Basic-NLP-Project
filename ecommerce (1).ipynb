{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613347a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ea8f3",
   "metadata": {},
   "source": [
    "* I have included all the required libraries in above cell.\n",
    "* Pandas and Numpy are used for data importing and data extracting to feed the for other libraries \n",
    "* Nltk is used for removing pre-processing of corpus\n",
    "* Word2Vec is also a preprocessing technique which is a neural network and helps in retaining semantic as well as syntatic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d951e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"ecommerceDataset.csv\",sep=',',names=[\"category\",\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a83194",
   "metadata": {},
   "source": [
    "* I have imported the file using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3103bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Micromax Canvas Win W121 (White)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50425 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          category                                        description\n",
       "0        Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1        Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2        Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3        Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4        Household  Incredible Gifts India Wooden Happy Birthday U...\n",
       "...            ...                                                ...\n",
       "50420  Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...\n",
       "50421  Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...\n",
       "50422  Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...\n",
       "50423  Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n",
       "50424  Electronics                   Micromax Canvas Win W121 (White)\n",
       "\n",
       "[50425 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d733cefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category       0\n",
       "description    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4014505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645b878",
   "metadata": {},
   "source": [
    "* In the above cell I have removed the one row which contains NAN value ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ea5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,len(df)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',df['description'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[words for words in review if not words in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ebadc",
   "metadata": {},
   "source": [
    "* In the above I am doing all the preprocessing of the data. I am removing all the stopwords such as I ,We ,They etc...\n",
    "* I am also removing any character except for Alphabets because alphabets form words and words are only required for the           training an NLP model.\n",
    "* I am also lower casing all the words because I dont lower case \"Apple\" and \"apple\" will be considered two diffferent words in   my corpus , which increases the vulnerability of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc649aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1=[]\n",
    "w_n=WordNetLemmatizer()\n",
    "for i in range(0,len(corpus)):\n",
    "    review=corpus[i]\n",
    "    review=[w_n.lemmatize(words) for words in review]\n",
    "    review=''.join(review)\n",
    "    corpus1.append(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e812d",
   "metadata": {},
   "source": [
    "* In the above code I have lemmatized my corpus which is a way of preprocessing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ebc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigger_list=[]\n",
    "for i in corpus1:\n",
    "     sub=list(i.split(' '))\n",
    "     Bigger_list.append(sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40661c8",
   "metadata": {},
   "source": [
    "* I have converted my \"corpus1\" into list of lists that is \"Bigger_list\". I have done this because word2Vec only accpets data     which is in form of list whithin a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1144e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df.iloc[:,0].values\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535bc3b",
   "metadata": {},
   "source": [
    "* I have converted my target variable into NLP model presentable  target varibale by using LabelEncoder and to_categorical. As     the target variable contains characters and words they need to converted into model understandble form as at the end of the     day machine learning is all about numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e094646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (Bigger_list,dummy_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8b10e",
   "metadata": {},
   "source": [
    "* I have splitted the corpus into Training and testing data. It is standard procedure followed by people to ensure they is no     overfitting on all data and testing data is used for validation of the predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b53a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(X_train,vector_size=500,min_count=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64bf17",
   "metadata": {},
   "source": [
    "* I have implemented the Word2Vec neural network . The vector_size is of 500 and min_count of each word in vector is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9418dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'size',\n",
       " 'book',\n",
       " 'set',\n",
       " 'use',\n",
       " 'one',\n",
       " 'easy',\n",
       " 'quality',\n",
       " 'high',\n",
       " 'black',\n",
       " 'also',\n",
       " 'product',\n",
       " 'made',\n",
       " 'home',\n",
       " 'design',\n",
       " 'author',\n",
       " 'cm',\n",
       " 'color',\n",
       " 'mm',\n",
       " 'new',\n",
       " 'time',\n",
       " 'power',\n",
       " 'cotton',\n",
       " 'best',\n",
       " 'usb',\n",
       " 'perfect',\n",
       " 'light',\n",
       " 'comes',\n",
       " 'make',\n",
       " 'features',\n",
       " 'used',\n",
       " 'material',\n",
       " 'women',\n",
       " 'water',\n",
       " 'long',\n",
       " 'designed',\n",
       " 'steel',\n",
       " 'life',\n",
       " 'free',\n",
       " 'inch',\n",
       " 'white',\n",
       " 'style',\n",
       " 'look',\n",
       " 'like',\n",
       " 'world',\n",
       " 'table',\n",
       " 'books',\n",
       " 'great',\n",
       " 'well',\n",
       " 'makes',\n",
       " 'men',\n",
       " 'soft',\n",
       " 'years',\n",
       " 'camera',\n",
       " 'top',\n",
       " 'india',\n",
       " 'colour',\n",
       " 'range',\n",
       " 'fit',\n",
       " 'cable',\n",
       " 'bluetooth',\n",
       " 'audio',\n",
       " 'fabric',\n",
       " 'name',\n",
       " 'stainless',\n",
       " 'room',\n",
       " 'kitchen',\n",
       " 'wear',\n",
       " 'v',\n",
       " 'wireless',\n",
       " 'work',\n",
       " 'plastic',\n",
       " 'get',\n",
       " 'products',\n",
       " 'even',\n",
       " 'easily',\n",
       " 'w',\n",
       " 'wall',\n",
       " 'without',\n",
       " 'experience',\n",
       " 'keep',\n",
       " 'g',\n",
       " 'pack',\n",
       " 'air',\n",
       " 'brand',\n",
       " 'hand',\n",
       " 'full',\n",
       " 'good',\n",
       " 'way',\n",
       " 'system',\n",
       " 'blue',\n",
       " 'every',\n",
       " 'length',\n",
       " 'storage',\n",
       " 'led',\n",
       " 'comfortable',\n",
       " 'clean',\n",
       " 'review',\n",
       " 'comfort',\n",
       " 'two',\n",
       " 'different',\n",
       " 'device',\n",
       " 'day',\n",
       " 'weight',\n",
       " 'gb',\n",
       " 'times',\n",
       " 'us',\n",
       " 'sound',\n",
       " 'card',\n",
       " 'ideal',\n",
       " 'technology',\n",
       " 'finish',\n",
       " 'back',\n",
       " 'provides',\n",
       " 'body',\n",
       " 'car',\n",
       " 'need',\n",
       " 'portable',\n",
       " 'battery',\n",
       " 'package',\n",
       " 'description',\n",
       " 'food',\n",
       " 'music',\n",
       " 'cleaning',\n",
       " 'first',\n",
       " 'lens',\n",
       " 'glass',\n",
       " 'inches',\n",
       " 'help',\n",
       " 'durable',\n",
       " 'speed',\n",
       " 'many',\n",
       " 'cover',\n",
       " 'support',\n",
       " 'phone',\n",
       " 'using',\n",
       " 'digital',\n",
       " 'p',\n",
       " 'stylish',\n",
       " 'speaker',\n",
       " 'content',\n",
       " 'small',\n",
       " 'space',\n",
       " 'making',\n",
       " 'available',\n",
       " 'non',\n",
       " 'type',\n",
       " 'machine',\n",
       " 'video',\n",
       " 'kids',\n",
       " 'performance',\n",
       " 'control',\n",
       " 'safe',\n",
       " 'may',\n",
       " 'multi',\n",
       " 'read',\n",
       " 'beautiful',\n",
       " 'office',\n",
       " 'university',\n",
       " 'give',\n",
       " 'year',\n",
       " 'etc',\n",
       " 'warranty',\n",
       " 'case',\n",
       " 'unique',\n",
       " 'go',\n",
       " 'compact',\n",
       " 'devices',\n",
       " 'students',\n",
       " 'red',\n",
       " 'built',\n",
       " 'dry',\n",
       " 'enjoy',\n",
       " 'gives',\n",
       " 'better',\n",
       " 'display',\n",
       " 'bag',\n",
       " 'people',\n",
       " 'mp',\n",
       " 'premium',\n",
       " 'adapter',\n",
       " 'piece',\n",
       " 'l',\n",
       " 'indian',\n",
       " 'box',\n",
       " 'pc',\n",
       " 'laptop',\n",
       " 'place',\n",
       " 'includes',\n",
       " 'handle',\n",
       " 'stand',\n",
       " 'baby',\n",
       " 'play',\n",
       " 'take',\n",
       " 'mobile',\n",
       " 'various',\n",
       " 'capacity',\n",
       " 'simple',\n",
       " 'metal',\n",
       " 'family',\n",
       " 'powerful',\n",
       " 'offers',\n",
       " 'protection',\n",
       " 'wide',\n",
       " 'large',\n",
       " 'including',\n",
       " 'feet',\n",
       " 'hd',\n",
       " 'please',\n",
       " 'b',\n",
       " 'standard',\n",
       " 'house',\n",
       " 'mini',\n",
       " 'screen',\n",
       " 'mind',\n",
       " 'e',\n",
       " 'must',\n",
       " 'c',\n",
       " 'feel',\n",
       " 'around',\n",
       " 'holder',\n",
       " 'allows',\n",
       " 'filter',\n",
       " 'clear',\n",
       " 'gift',\n",
       " 'function',\n",
       " 'wash',\n",
       " 'provide',\n",
       " 'compatible',\n",
       " 'pcs',\n",
       " 'love',\n",
       " 'right',\n",
       " 'girls',\n",
       " 'works',\n",
       " 'modern',\n",
       " 'wood',\n",
       " 'drive',\n",
       " 'n',\n",
       " 'smart',\n",
       " 'want',\n",
       " 'touch',\n",
       " 'dust',\n",
       " 'hard',\n",
       " 'much',\n",
       " 'feature',\n",
       " 'helps',\n",
       " 'silver',\n",
       " 'furniture',\n",
       " 'suitable',\n",
       " 'super',\n",
       " 'hours',\n",
       " 'level',\n",
       " 'collection',\n",
       " 'science',\n",
       " 'highly',\n",
       " 'carry',\n",
       " 'included',\n",
       " 'see',\n",
       " 'natural',\n",
       " 'low',\n",
       " 'convenient',\n",
       " 'history',\n",
       " 'colors',\n",
       " 'plus',\n",
       " 'heat',\n",
       " 'elegant',\n",
       " 'output',\n",
       " 'living',\n",
       " 'surface',\n",
       " 'needs',\n",
       " 'note',\n",
       " 'computer',\n",
       " 'skin',\n",
       " 'store',\n",
       " 'r',\n",
       " 'night',\n",
       " 'accessories',\n",
       " 'special',\n",
       " 'paper',\n",
       " 'side',\n",
       " 'plug',\n",
       " 'children',\n",
       " 'ensure',\n",
       " 'inside',\n",
       " 'item',\n",
       " 'research',\n",
       " 'brown',\n",
       " 'guide',\n",
       " 'extra',\n",
       " 'single',\n",
       " 'would',\n",
       " 'business',\n",
       " 'data',\n",
       " 'port',\n",
       " 'print',\n",
       " 'fan',\n",
       " 'team',\n",
       " 'chair',\n",
       " 'lightweight',\n",
       " 'f',\n",
       " 'clothes',\n",
       " 'art',\n",
       " 'mode',\n",
       " 'connect',\n",
       " 'warm',\n",
       " 'international',\n",
       " 'professional',\n",
       " 'care',\n",
       " 'latest',\n",
       " 'series',\n",
       " 'kit',\n",
       " 'front',\n",
       " 'shirt',\n",
       " 'height',\n",
       " 'ultra',\n",
       " 'memory',\n",
       " 'important',\n",
       " 'wooden',\n",
       " 'windows',\n",
       " 'add',\n",
       " 'smooth',\n",
       " 'temperature',\n",
       " 'school',\n",
       " 'fast',\n",
       " 'little',\n",
       " 'complete',\n",
       " 'tool',\n",
       " 'round',\n",
       " 'door',\n",
       " 'quick',\n",
       " 'charging',\n",
       " 'come',\n",
       " 'button',\n",
       " 'ml',\n",
       " 'k',\n",
       " 'kg',\n",
       " 'story',\n",
       " 'pieces',\n",
       " 'vacuum',\n",
       " 'decor',\n",
       " 'watt',\n",
       " 'key',\n",
       " 'classic',\n",
       " 'sports',\n",
       " 'ensures',\n",
       " 'double',\n",
       " 'player',\n",
       " 'professor',\n",
       " 'per',\n",
       " 'strong',\n",
       " 'york',\n",
       " 'anti',\n",
       " 'hot',\n",
       " 'self',\n",
       " 'solid',\n",
       " 'dual',\n",
       " 'fashion',\n",
       " 'switch',\n",
       " 'boys',\n",
       " 'manual',\n",
       " 'bathroom',\n",
       " 'sure',\n",
       " 'base',\n",
       " 'yes',\n",
       " 'h',\n",
       " 'choice',\n",
       " 'outdoor',\n",
       " 'shape',\n",
       " 'regular',\n",
       " 'resistant',\n",
       " 'class',\n",
       " 'coffee',\n",
       " 'put',\n",
       " 'three',\n",
       " 'green',\n",
       " 'friendly',\n",
       " 'cloth',\n",
       " 'lives',\n",
       " 'head',\n",
       " 'based',\n",
       " 'cool',\n",
       " 'part',\n",
       " 'dvd',\n",
       " 'number',\n",
       " 'safety',\n",
       " 'degree',\n",
       " 'rich',\n",
       " 'fine',\n",
       " 'since',\n",
       " 'party',\n",
       " 'cooking',\n",
       " 'casual',\n",
       " 'bed',\n",
       " 'buy',\n",
       " 'travel',\n",
       " 'along',\n",
       " 'daily',\n",
       " 'micro',\n",
       " 'image',\n",
       " 'adjustable',\n",
       " 'never',\n",
       " 'written',\n",
       " 'due',\n",
       " 'voltage',\n",
       " 'effective',\n",
       " 'solution',\n",
       " 'looking',\n",
       " 'frame',\n",
       " 'short',\n",
       " 'simply',\n",
       " 'online',\n",
       " 'maximum',\n",
       " 'exam',\n",
       " 'attractive',\n",
       " 'pair',\n",
       " 'grey',\n",
       " 'iron',\n",
       " 'working',\n",
       " 'brings',\n",
       " 'speakers',\n",
       " 'slim',\n",
       " 'multiple',\n",
       " 'last',\n",
       " 'find',\n",
       " 'superior',\n",
       " 'cleaner',\n",
       " 'board',\n",
       " 'waist',\n",
       " 'stick',\n",
       " 'cut',\n",
       " 'electric',\n",
       " 'grade',\n",
       " 'edition',\n",
       " 'waterproof',\n",
       " 'traditional',\n",
       " 'health',\n",
       " 'unit',\n",
       " 'max',\n",
       " 'always',\n",
       " 'grip',\n",
       " 'big',\n",
       " 'heavy',\n",
       " 'proof',\n",
       " 'real',\n",
       " 'today',\n",
       " 'create',\n",
       " 'washing',\n",
       " 'tv',\n",
       " 'width',\n",
       " 'tools',\n",
       " 'open',\n",
       " 'stereo',\n",
       " 'keeping',\n",
       " 'ready',\n",
       " 'press',\n",
       " 'pro',\n",
       " 'whole',\n",
       " 'age',\n",
       " 'user',\n",
       " 'service',\n",
       " 'fresh',\n",
       " 'sturdy',\n",
       " 'maternity',\n",
       " 'excellent',\n",
       " 'model',\n",
       " 'energy',\n",
       " 'printed',\n",
       " 'hold',\n",
       " 'useful',\n",
       " 'writing',\n",
       " 'bottom',\n",
       " 'pocket',\n",
       " 'fun',\n",
       " 'step',\n",
       " 'human',\n",
       " 'reading',\n",
       " 'mount',\n",
       " 'specifications',\n",
       " 'english',\n",
       " 'ac',\n",
       " 'combo',\n",
       " 'gold',\n",
       " 'dress',\n",
       " 'designs',\n",
       " 'pattern',\n",
       " 'less',\n",
       " 'keyboard',\n",
       " 'manufacturer',\n",
       " 'crafted',\n",
       " 'lamp',\n",
       " 'monitor',\n",
       " 'knowledge',\n",
       " 'socks',\n",
       " 'ease',\n",
       " 'approx',\n",
       " 'iphone',\n",
       " 'tripod',\n",
       " 'external',\n",
       " 'tea',\n",
       " 'old',\n",
       " 'bra',\n",
       " 'covers',\n",
       " 'study',\n",
       " 'amazon',\n",
       " 'panel',\n",
       " 'resolution',\n",
       " 'bar',\n",
       " 'auto',\n",
       " 'end',\n",
       " 'durability',\n",
       " 'change',\n",
       " 'protect',\n",
       " 'ever',\n",
       " 'rack',\n",
       " 'noise',\n",
       " 'line',\n",
       " 'away',\n",
       " 'yet',\n",
       " 'angle',\n",
       " 'access',\n",
       " 'lock',\n",
       " 'national',\n",
       " 'mirror',\n",
       " 'center',\n",
       " 'u',\n",
       " 'sd',\n",
       " 'know',\n",
       " 'four',\n",
       " 'offer',\n",
       " 'brush',\n",
       " 'american',\n",
       " 'fm',\n",
       " 'looks',\n",
       " 'dr',\n",
       " 'required',\n",
       " 'flash',\n",
       " 'reader',\n",
       " 'items',\n",
       " 'include',\n",
       " 'security',\n",
       " 'dimensions',\n",
       " 'core',\n",
       " 'supports',\n",
       " 'automatic',\n",
       " 'essential',\n",
       " 'input',\n",
       " 'picture',\n",
       " 'foot',\n",
       " 'remote',\n",
       " 'addition',\n",
       " 'tablet',\n",
       " 'friends',\n",
       " 'fully',\n",
       " 'hp',\n",
       " 'dark',\n",
       " 'bring',\n",
       " 'purpose',\n",
       " 'eye',\n",
       " 'practical',\n",
       " 'view',\n",
       " 'cd',\n",
       " 'cup',\n",
       " 'test',\n",
       " 'area',\n",
       " 'belt',\n",
       " 'installation',\n",
       " 'pure',\n",
       " 'media',\n",
       " 'materials',\n",
       " 'advanced',\n",
       " 'motor',\n",
       " 'bass',\n",
       " 'let',\n",
       " 'sizes',\n",
       " 'known',\n",
       " 'leading',\n",
       " 'trendy',\n",
       " 'neck',\n",
       " 'android',\n",
       " 'keeps',\n",
       " 'volume',\n",
       " 'universal',\n",
       " 'towel',\n",
       " 'charger',\n",
       " 'requirements',\n",
       " 'hdmi',\n",
       " 'th',\n",
       " 'hz',\n",
       " 'start',\n",
       " 'multicolour',\n",
       " 'photo',\n",
       " 'suit',\n",
       " 'hands',\n",
       " 'bedroom',\n",
       " 'could',\n",
       " 'award',\n",
       " 'ft',\n",
       " 'company',\n",
       " 'hanging',\n",
       " 'management',\n",
       " 'enough',\n",
       " 'lasting',\n",
       " 'cord',\n",
       " 'dining',\n",
       " 'steam',\n",
       " 'writer',\n",
       " 'personal',\n",
       " 'pink',\n",
       " 'general',\n",
       " 'original',\n",
       " 'together',\n",
       " 'game',\n",
       " 'oil',\n",
       " 'think',\n",
       " 'sleeve',\n",
       " 'anywhere',\n",
       " 'information',\n",
       " 'fits',\n",
       " 'floor',\n",
       " 'questions',\n",
       " 'point',\n",
       " 'network',\n",
       " 'fi',\n",
       " 'diameter',\n",
       " 'practice',\n",
       " 'wire',\n",
       " 'decorative',\n",
       " 'wet',\n",
       " 'everyday',\n",
       " 'whether',\n",
       " 'lid',\n",
       " 'cutting',\n",
       " 'education',\n",
       " 'mouse',\n",
       " 'chapter',\n",
       " 'child',\n",
       " 'wardrobe',\n",
       " 'public',\n",
       " 'deep',\n",
       " 'optical',\n",
       " 'contact',\n",
       " 'published',\n",
       " 'film',\n",
       " 'face',\n",
       " 'copper',\n",
       " 'slip',\n",
       " 'everything',\n",
       " 'several',\n",
       " 'shower',\n",
       " 'connection',\n",
       " 'efficient',\n",
       " 'leather',\n",
       " 'thermal',\n",
       " 'wi',\n",
       " 'experts',\n",
       " 'desktop',\n",
       " 'next',\n",
       " 'form',\n",
       " 'remove',\n",
       " 'become',\n",
       " 'winter',\n",
       " 'cold',\n",
       " 'frequency',\n",
       " 'knife',\n",
       " 'extremely',\n",
       " 'engineering',\n",
       " 'college',\n",
       " 'lighting',\n",
       " 'lights',\n",
       " 'maker',\n",
       " 'flexible',\n",
       " 'bottle',\n",
       " 'uses',\n",
       " 'stories',\n",
       " 'contains',\n",
       " 'learning',\n",
       " 'medical',\n",
       " 'images',\n",
       " 'basic',\n",
       " 'edge',\n",
       " 'com',\n",
       " 'microphone',\n",
       " 'value',\n",
       " 'specification',\n",
       " 'usage',\n",
       " 'accessory',\n",
       " 'cameras',\n",
       " 'days',\n",
       " 'polyester',\n",
       " 'basket',\n",
       " 'post',\n",
       " 'curtain',\n",
       " 'mic',\n",
       " 'operating',\n",
       " 'details',\n",
       " 'band',\n",
       " 'process',\n",
       " 'operation',\n",
       " 'choose',\n",
       " 'charge',\n",
       " 'transfer',\n",
       " 'variety',\n",
       " 'within',\n",
       " 'innovative',\n",
       " 'supply',\n",
       " 'minutes',\n",
       " 'live',\n",
       " 'money',\n",
       " 'handy',\n",
       " 'turn',\n",
       " 'contemporary',\n",
       " 'things',\n",
       " 'heater',\n",
       " 'garden',\n",
       " 'connectivity',\n",
       " 'popular',\n",
       " 'readers',\n",
       " 'radio',\n",
       " 'window',\n",
       " 'dirt',\n",
       " 'language',\n",
       " 'apple',\n",
       " 'training',\n",
       " 'kurta',\n",
       " 'photos',\n",
       " 'order',\n",
       " 'distance',\n",
       " 'true',\n",
       " 'receive',\n",
       " 'transparent',\n",
       " 'current',\n",
       " 'quickly',\n",
       " 'blade',\n",
       " 'blades',\n",
       " 'amazing',\n",
       " 'cabinet',\n",
       " 'longer',\n",
       " 'receiver',\n",
       " 'batteries',\n",
       " 'born',\n",
       " 'favourite',\n",
       " 'across',\n",
       " 'beauty',\n",
       " 'colours',\n",
       " 'allow',\n",
       " 'shoes',\n",
       " 'lcd',\n",
       " 'sunglasses',\n",
       " 'star',\n",
       " 'male',\n",
       " 'sleek',\n",
       " 'decoration',\n",
       " 'combination',\n",
       " 'saving',\n",
       " 'settings',\n",
       " 'ice',\n",
       " 'bags',\n",
       " 'pre',\n",
       " 'healthy',\n",
       " 'ring',\n",
       " 'pvc',\n",
       " 'recording',\n",
       " 'egg',\n",
       " 'avoid',\n",
       " 'functions',\n",
       " 'field',\n",
       " 'gaming',\n",
       " 'internet',\n",
       " 'rubber',\n",
       " 'master',\n",
       " 'focus',\n",
       " 'silk',\n",
       " 'vary',\n",
       " 'voice',\n",
       " 'smartphone',\n",
       " 'ceramic',\n",
       " 'install',\n",
       " 'bean',\n",
       " 'faster',\n",
       " 'software',\n",
       " 'anyone',\n",
       " 'medium',\n",
       " 'check',\n",
       " 'equipped',\n",
       " 'hook',\n",
       " 'running',\n",
       " 'photography',\n",
       " 'multipurpose',\n",
       " 'five',\n",
       " 'desk',\n",
       " 'source',\n",
       " 'strap',\n",
       " 'perfectly',\n",
       " 'sharp',\n",
       " 'indoor',\n",
       " 'uv',\n",
       " 'lets',\n",
       " 'pad',\n",
       " 'text',\n",
       " 'db',\n",
       " 'past',\n",
       " 'formal',\n",
       " 'completely',\n",
       " 'position',\n",
       " 'silicone',\n",
       " 'professionals',\n",
       " 'understand',\n",
       " 'save',\n",
       " 'samsung',\n",
       " 'ports',\n",
       " 'state',\n",
       " 'wearing',\n",
       " 'suction',\n",
       " 'enhance',\n",
       " 'sony',\n",
       " 'shoe',\n",
       " 'upto',\n",
       " 'pressure',\n",
       " 'bowl',\n",
       " 'pictures',\n",
       " 'serving',\n",
       " 'success',\n",
       " 'favorite',\n",
       " 'action',\n",
       " 'plate',\n",
       " 'market',\n",
       " 'nature',\n",
       " 'dc',\n",
       " 'prevent',\n",
       " 'yellow',\n",
       " 'aplus',\n",
       " 'blend',\n",
       " 'connector',\n",
       " 'cap',\n",
       " 'amazonbasics',\n",
       " 'environment',\n",
       " 'pillow',\n",
       " 'show',\n",
       " 'specially',\n",
       " 'girl',\n",
       " 'clock',\n",
       " 'clip',\n",
       " 'flat',\n",
       " 'man',\n",
       " 'effect',\n",
       " 'watts',\n",
       " 'square',\n",
       " 'pin',\n",
       " 'directly',\n",
       " 'surfaces',\n",
       " 'elastic',\n",
       " 'signal',\n",
       " 'institute',\n",
       " 'aux',\n",
       " 'price',\n",
       " 'secure',\n",
       " 'construction',\n",
       " 'providing',\n",
       " 'director',\n",
       " 'main',\n",
       " 'mbps',\n",
       " 'glasses',\n",
       " 'development',\n",
       " 'sofa',\n",
       " 'convenience',\n",
       " 'option',\n",
       " 'instant',\n",
       " 'papers',\n",
       " 'gsm',\n",
       " 'ipad',\n",
       " 'keys',\n",
       " 'hair',\n",
       " 'stay',\n",
       " 'almost',\n",
       " 'drawer',\n",
       " 'total',\n",
       " 'bestselling',\n",
       " 'strength',\n",
       " 'net',\n",
       " 'recommended',\n",
       " 'sleep',\n",
       " 'bright',\n",
       " 'thanks',\n",
       " 'powered',\n",
       " 'analysis',\n",
       " 'bath',\n",
       " 'ram',\n",
       " 'designer',\n",
       " 'understanding',\n",
       " 'call',\n",
       " 'another',\n",
       " 'foldable',\n",
       " 'coated',\n",
       " 'eyes',\n",
       " 'pan',\n",
       " 'container',\n",
       " 'videos',\n",
       " 'tray',\n",
       " 'connected',\n",
       " 'versatile',\n",
       " 'sensor',\n",
       " 'ghz',\n",
       " 'bank',\n",
       " 'move',\n",
       " 'spray',\n",
       " 'electronic',\n",
       " 'novel',\n",
       " 'screw',\n",
       " 'layer',\n",
       " 'jacket',\n",
       " 'systems',\n",
       " 'shorts',\n",
       " 'phones',\n",
       " 'might',\n",
       " 'carefully',\n",
       " 'nursing',\n",
       " 'crystal',\n",
       " 'medicine',\n",
       " 'aluminium',\n",
       " 'second',\n",
       " 'creative',\n",
       " 'featuring',\n",
       " 'interface',\n",
       " 'still',\n",
       " 'thus',\n",
       " 'stop',\n",
       " 'co',\n",
       " 'accurate',\n",
       " 'subject',\n",
       " 'technical',\n",
       " 'slightly',\n",
       " 'link',\n",
       " 'headphones',\n",
       " 'automatically',\n",
       " 'delhi',\n",
       " 'tie',\n",
       " 'question',\n",
       " 'processor',\n",
       " 'behind',\n",
       " 'cushion',\n",
       " 'chrome',\n",
       " 'services',\n",
       " 'tank',\n",
       " 'giving',\n",
       " 'methods',\n",
       " 'customers',\n",
       " 'clothing',\n",
       " 'worry',\n",
       " 'royal',\n",
       " 'enables',\n",
       " 'jbl',\n",
       " 'country',\n",
       " 'normal',\n",
       " 'takes',\n",
       " 'inner',\n",
       " 'format',\n",
       " 'examinations',\n",
       " 'laundry',\n",
       " 'lifestyle',\n",
       " 'months',\n",
       " 'channel',\n",
       " 'results',\n",
       " 'additional',\n",
       " 'capture',\n",
       " 'prevents',\n",
       " 'drying',\n",
       " 'damage',\n",
       " 'possible',\n",
       " 'pregnancy',\n",
       " 'meter',\n",
       " 'heating',\n",
       " 'canon',\n",
       " 'abs',\n",
       " 'zoom',\n",
       " 'setting',\n",
       " 'half',\n",
       " 'heart',\n",
       " 'cards',\n",
       " 'learn',\n",
       " 'customer',\n",
       " 'left',\n",
       " 'paint',\n",
       " 'everyone',\n",
       " 'ones',\n",
       " 'percent',\n",
       " 'calls',\n",
       " 'pen',\n",
       " 'compatibility',\n",
       " 'rust',\n",
       " 'areas',\n",
       " 'mah',\n",
       " 'delivers',\n",
       " 'types',\n",
       " 'needed',\n",
       " 'highest',\n",
       " 'group',\n",
       " 'ethnic',\n",
       " 'flow',\n",
       " 'folding',\n",
       " 'rechargeable',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.index_to_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b402efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.200739</td>\n",
       "      <td>-0.195618</td>\n",
       "      <td>0.519429</td>\n",
       "      <td>1.080256</td>\n",
       "      <td>-0.750230</td>\n",
       "      <td>0.132412</td>\n",
       "      <td>-0.593700</td>\n",
       "      <td>0.956430</td>\n",
       "      <td>-0.607862</td>\n",
       "      <td>-0.126475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607304</td>\n",
       "      <td>-0.815473</td>\n",
       "      <td>0.263435</td>\n",
       "      <td>-0.427634</td>\n",
       "      <td>-0.031694</td>\n",
       "      <td>-0.624634</td>\n",
       "      <td>1.111764</td>\n",
       "      <td>0.484459</td>\n",
       "      <td>0.990387</td>\n",
       "      <td>0.528301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>-0.825594</td>\n",
       "      <td>0.356079</td>\n",
       "      <td>0.573316</td>\n",
       "      <td>0.478548</td>\n",
       "      <td>-1.197532</td>\n",
       "      <td>-0.142884</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>0.484288</td>\n",
       "      <td>-1.516412</td>\n",
       "      <td>0.059512</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.144145</td>\n",
       "      <td>0.717527</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.458191</td>\n",
       "      <td>1.506234</td>\n",
       "      <td>-0.885418</td>\n",
       "      <td>-0.990446</td>\n",
       "      <td>0.568659</td>\n",
       "      <td>1.034311</td>\n",
       "      <td>0.647028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>-0.026073</td>\n",
       "      <td>-0.401894</td>\n",
       "      <td>1.868490</td>\n",
       "      <td>-1.545737</td>\n",
       "      <td>0.376533</td>\n",
       "      <td>-0.007971</td>\n",
       "      <td>-0.979492</td>\n",
       "      <td>-0.049779</td>\n",
       "      <td>-0.036002</td>\n",
       "      <td>-0.778212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348064</td>\n",
       "      <td>-0.347594</td>\n",
       "      <td>0.265368</td>\n",
       "      <td>0.615477</td>\n",
       "      <td>0.715497</td>\n",
       "      <td>-0.269789</td>\n",
       "      <td>-0.492135</td>\n",
       "      <td>-0.718247</td>\n",
       "      <td>-1.668540</td>\n",
       "      <td>-0.847314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <td>0.511687</td>\n",
       "      <td>-0.163344</td>\n",
       "      <td>-0.047670</td>\n",
       "      <td>0.300243</td>\n",
       "      <td>-0.574466</td>\n",
       "      <td>0.678101</td>\n",
       "      <td>-0.460112</td>\n",
       "      <td>-0.059032</td>\n",
       "      <td>-0.644324</td>\n",
       "      <td>1.047236</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.339235</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>-1.309904</td>\n",
       "      <td>1.475975</td>\n",
       "      <td>-1.224585</td>\n",
       "      <td>-0.983603</td>\n",
       "      <td>-0.242972</td>\n",
       "      <td>1.936243</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>-0.009123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.347441</td>\n",
       "      <td>0.642710</td>\n",
       "      <td>-0.139679</td>\n",
       "      <td>1.814078</td>\n",
       "      <td>-0.101757</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.097853</td>\n",
       "      <td>0.742256</td>\n",
       "      <td>0.177960</td>\n",
       "      <td>0.823247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055774</td>\n",
       "      <td>-1.155108</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.802216</td>\n",
       "      <td>-0.532556</td>\n",
       "      <td>-1.618827</td>\n",
       "      <td>0.557069</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>1.554201</td>\n",
       "      <td>-1.956362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satva</th>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>-0.005851</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>-0.012754</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>-0.009291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excelmost</th>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>-0.010643</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>-0.009196</td>\n",
       "      <td>-0.013614</td>\n",
       "      <td>-0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screenshots</th>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.005607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>-0.010732</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>-0.020901</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>-0.010377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataestimating</th>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>-0.007901</td>\n",
       "      <td>-0.011619</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>-0.003572</td>\n",
       "      <td>-0.021825</td>\n",
       "      <td>-0.031035</td>\n",
       "      <td>-0.013949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modaks</th>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.014040</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>-0.015823</td>\n",
       "      <td>-0.002382</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>-0.003913</td>\n",
       "      <td>-0.017125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46110 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5    \\\n",
       "x               0.200739 -0.195618  0.519429  1.080256 -0.750230  0.132412   \n",
       "size           -0.825594  0.356079  0.573316  0.478548 -1.197532 -0.142884   \n",
       "book           -0.026073 -0.401894  1.868490 -1.545737  0.376533 -0.007971   \n",
       "set             0.511687 -0.163344 -0.047670  0.300243 -0.574466  0.678101   \n",
       "use             0.347441  0.642710 -0.139679  1.814078 -0.101757  0.459244   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "satva           0.006704  0.004658  0.008026  0.007224 -0.005851 -0.004528   \n",
       "excelmost       0.012756  0.015102  0.006346  0.014200  0.013223 -0.000036   \n",
       "screenshots     0.011299  0.007594  0.020019  0.002228  0.014310 -0.001884   \n",
       "dataestimating  0.011320  0.018989  0.012182  0.015734 -0.007901 -0.011619   \n",
       "modaks          0.003575  0.012499  0.014040  0.011788  0.007260  0.014824   \n",
       "\n",
       "                     6         7         8         9    ...       490  \\\n",
       "x              -0.593700  0.956430 -0.607862 -0.126475  ...  0.607304   \n",
       "size            0.034866  0.484288 -1.516412  0.059512  ... -1.144145   \n",
       "book           -0.979492 -0.049779 -0.036002 -0.778212  ...  0.348064   \n",
       "set            -0.460112 -0.059032 -0.644324  1.047236  ... -1.339235   \n",
       "use             0.097853  0.742256  0.177960  0.823247  ... -0.055774   \n",
       "...                  ...       ...       ...       ...  ...       ...   \n",
       "satva          -0.004777  0.011995  0.009675  0.000457  ...  0.007588   \n",
       "excelmost      -0.003541  0.026129  0.005805  0.001942  ...  0.016410   \n",
       "screenshots    -0.001195  0.018966  0.003461 -0.005607  ...  0.004951   \n",
       "dataestimating  0.018604  0.036855  0.010602  0.001165  ...  0.007703   \n",
       "modaks          0.005704  0.016992  0.010926  0.014928  ...  0.003407   \n",
       "\n",
       "                     491       492       493       494       495       496  \\\n",
       "x              -0.815473  0.263435 -0.427634 -0.031694 -0.624634  1.111764   \n",
       "size            0.717527  0.102362  0.458191  1.506234 -0.885418 -0.990446   \n",
       "book           -0.347594  0.265368  0.615477  0.715497 -0.269789 -0.492135   \n",
       "set            -0.018179 -1.309904  1.475975 -1.224585 -0.983603 -0.242972   \n",
       "use            -1.155108  0.468200  0.802216 -0.532556 -1.618827  0.557069   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "satva           0.004485 -0.001247 -0.000720  0.002118 -0.000915  0.003126   \n",
       "excelmost      -0.001464  0.012047 -0.010643  0.003176  0.015003  0.009187   \n",
       "screenshots    -0.008279  0.027193 -0.010732  0.008167  0.006825  0.011112   \n",
       "dataestimating -0.002834  0.036071  0.004418  0.010796  0.012752 -0.003572   \n",
       "modaks         -0.001495 -0.006419  0.002621 -0.015823 -0.002382  0.017183   \n",
       "\n",
       "                     497       498       499  \n",
       "x               0.484459  0.990387  0.528301  \n",
       "size            0.568659  1.034311  0.647028  \n",
       "book           -0.718247 -1.668540 -0.847314  \n",
       "set             1.936243  0.770754 -0.009123  \n",
       "use             0.000838  1.554201 -1.956362  \n",
       "...                  ...       ...       ...  \n",
       "satva          -0.012754 -0.001726 -0.009291  \n",
       "excelmost      -0.009196 -0.013614 -0.001073  \n",
       "screenshots    -0.020901 -0.006072 -0.010377  \n",
       "dataestimating -0.021825 -0.031035 -0.013949  \n",
       "modaks         -0.009987 -0.003913 -0.017125  \n",
       "\n",
       "[46110 rows x 500 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [w2v_model.wv.get_vector(str(n)) for n in w2v_model.wv.key_to_index],\n",
    "        index = w2v_model.wv.key_to_index\n",
    "    )\n",
    ")\n",
    "emb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054255f5",
   "metadata": {},
   "source": [
    "* The above data frame shows us the similarity of each word with the corpus obtained from word2Vec (the 500 words) . \n",
    "* The closer the they are the similar they are ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f263728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohd Arafat\\AppData\\Local\\Temp\\ipykernel_17280\\3620852164.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40339,) (10085,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohd Arafat\\AppData\\Local\\Temp\\ipykernel_17280\\3620852164.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n"
     ]
    }
   ],
   "source": [
    "words = set(w2v_model.wv.index_to_key )\n",
    "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_train])\n",
    "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269b740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(500, dtype=float))\n",
    "        \n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(500, dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973c172",
   "metadata": {},
   "source": [
    "* The above are the pre processing of Word2vec to ensure that all the vectors have same size ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6596ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train_vect_avg, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf195f11",
   "metadata": {},
   "source": [
    "* I have used RandForestClassifier for classifing my data. I have choosen RandomForestClassifier randomly . There is no specific   reason for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e8e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test_vect_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7c3dd",
   "metadata": {},
   "source": [
    "* I have predicted the model work by using my \"Testing Data\".\n",
    "* I have used metrics like precision , accuracy and recall_score to show how my model works .\n",
    "* As I have used in my below cell all the performance metrics are pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba59a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.982628777989758 \n",
      "Recall: 0.9703520079325731 \n",
      "Accuracy: 0.9703520079325731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "precision = precision_score(y_test, y_pred,average='micro')\n",
    "recall = recall_score(y_test, y_pred,average='micro')\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "print('''Precision: {} \n",
    "Recall: {} \n",
    "Accuracy: {}'''.format(\n",
    "    precision, recall,accuracy ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
